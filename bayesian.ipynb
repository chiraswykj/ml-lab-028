{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108b778b-16f6-4749-bec3-715cac8abebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ucimlrepo) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ucimlrepo) (2025.4.26)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0c1601-0e1e-432d-a6b1-c492fa3ee4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                            Ellipsis\n",
      "0.00 0.64 0.64 0.0 0.32 0.00 0.00 0.00 0.00 0.00 0.00 0.64 0.00 0.00 0.00 0.32 0.00 1.29 1.93 0.00 0.96 0.0 0.00 0.00 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.00 0.0 0.0 0.00 0.0 0.0 0.00 0.0 0.00 0.00 0.0 0.0 0.00 0.000 0.0 0.778 0.000 0.000 3.756 61  278          1\n",
      "0.21 0.28 0.50 0.0 0.14 0.28 0.21 0.07 0.00 0.94 0.21 0.79 0.65 0.21 0.14 0.14 0.07 0.28 3.47 0.00 1.59 0.0 0.43 0.43 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.07 0.0 0.0 0.00 0.0 0.0 0.00 0.0 0.00 0.00 0.0 0.0 0.00 0.132 0.0 0.372 0.180 0.048 5.114 101 1028         1\n",
      "0.06 0.00 0.71 0.0 1.23 0.19 0.19 0.12 0.64 0.25 0.38 0.45 0.12 0.00 1.75 0.06 0.06 1.03 1.36 0.32 0.51 0.0 1.16 0.06 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.00 0.0 0.0 0.06 0.0 0.0 0.12 0.0 0.06 0.06 0.0 0.0 0.01 0.143 0.0 0.276 0.184 0.010 9.821 485 2259         1\n",
      "0.00 0.00 0.00 0.0 0.63 0.00 0.31 0.63 0.31 0.63 0.31 0.31 0.31 0.00 0.00 0.31 0.00 0.00 3.18 0.00 0.31 0.0 0.00 0.00 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.00 0.0 0.0 0.00 0.0 0.0 0.00 0.0 0.00 0.00 0.0 0.0 0.00 0.137 0.0 0.137 0.000 0.000 3.537 40  191          1\n",
      "                                                                                                                                                                                                                                0.135 0.0 0.135 0.000 0.000 3.537 40  191          1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "# For some datasets, you might need to specify column names manually\n",
    "column_names = [ ... ]  # provide list of feature names if available\n",
    "\n",
    "df = pd.read_csv(url, header=None, names=column_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef9bcbf-bfde-4bfc-8eb6-d5a4ee29b066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probabilities:\n",
      "P(class=0) = 0.6133\n",
      "P(class=1) = 0.3867\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245 286]\n",
      " [  5 385]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.46      0.63       531\n",
      "           1       0.57      0.99      0.73       390\n",
      "\n",
      "    accuracy                           0.68       921\n",
      "   macro avg       0.78      0.72      0.68       921\n",
      "weighted avg       0.81      0.68      0.67       921\n",
      "\n",
      "Accuracy: 0.6840390879478827\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# === Step 1: Load dataset ===\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "\n",
    "# Column names from the dataset description (you can also skip or customize)\n",
    "columns = [\n",
    "    \"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \"word_freq_our\",\n",
    "    \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \"word_freq_order\", \"word_freq_mail\",\n",
    "    \"word_freq_receive\", \"word_freq_will\", \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\",\n",
    "    \"word_freq_free\", \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\",\n",
    "    \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\",\n",
    "    \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\",\n",
    "    \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\",\n",
    "    \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "    \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\",\n",
    "    \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\",\n",
    "    \"char_freq_;\", \"char_freq_(\", \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_#\",\n",
    "    \"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\",\n",
    "    \"spam\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# === Step 2: Prepare data ===\n",
    "X = df.drop(\"spam\", axis=1).values\n",
    "y = df[\"spam\"].values\n",
    "\n",
    "# === Step 3: Train-test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Step 4: Calculate prior probabilities ===\n",
    "classes = np.unique(y_train)\n",
    "priors = {cls: np.mean(y_train == cls) for cls in classes}\n",
    "print(\"Prior probabilities:\")\n",
    "for cls in priors:\n",
    "    print(f\"P(class={cls}) = {priors[cls]:.4f}\")\n",
    "\n",
    "# === Step 5: Calculate mean and variance for each feature per class ===\n",
    "means = {}\n",
    "variances = {}\n",
    "for cls in classes:\n",
    "    X_cls = X_train[y_train == cls]\n",
    "    means[cls] = X_cls.mean(axis=0)\n",
    "    variances[cls] = X_cls.var(axis=0) + 1e-6  # add epsilon for stability\n",
    "\n",
    "# === Step 6: Gaussian likelihood function ===\n",
    "def gaussian_likelihood(x, mean, var):\n",
    "    coeff = 1.0 / np.sqrt(2 * np.pi * var)\n",
    "    exponent = np.exp(- (x - mean)**2 / (2 * var))\n",
    "    return coeff * exponent\n",
    "\n",
    "# === Step 7: Prediction function ===\n",
    "def predict(X):\n",
    "    y_pred = []\n",
    "    for x in X:\n",
    "        posteriors = {}\n",
    "        for cls in classes:\n",
    "            prior_log = np.log(priors[cls])\n",
    "            likelihoods = gaussian_likelihood(x, means[cls], variances[cls])\n",
    "            likelihoods = np.clip(likelihoods, 1e-9, None)  # avoid log(0)\n",
    "            likelihood_log = np.sum(np.log(likelihoods))\n",
    "            posteriors[cls] = prior_log + likelihood_log\n",
    "        y_pred.append(max(posteriors, key=posteriors.get))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# === Step 8: Predict on test data ===\n",
    "y_pred = predict(X_test)\n",
    "\n",
    "# === Step 9: Evaluate ===\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303dcfd8-d6d5-4ce1-95ee-c8354d4e2de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
